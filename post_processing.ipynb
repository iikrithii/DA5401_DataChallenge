{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c289b853",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from groq import Groq\n",
    "from tqdm import tqdm\n",
    "import fasttext\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232f4eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "GROQ_API_KEY = \"GROQKEY\" \n",
    "INPUT_JSON_PATH = \"test_data.json\"       \n",
    "INPUT_SCORES_PATH = \"submission_metric_shuffle.csv\"    \n",
    "OUTPUT_CSV_PATH = \"updated_submission_metric_shuffle.csv\"   \n",
    "FASTTEXT_PATH = \"lid.176.bin\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f03f1d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keyword mapping\n",
    "KEYWORD_MAPPING = {\n",
    "    \"rejection_rate\": [\"rejection\"],\n",
    "    \"ner_performance_for_the_relevant_entities\": [\"ner\", \"entities\"],\n",
    "    \"confidence_agreement\": [\"confidence\"],\n",
    "    \"bias_assessment\": [\"bias\"],\n",
    "    \"privacy_leakage\": [\"privacy\"],\n",
    "    \"data_governance_policies\": [\"governance\", \"data\"],\n",
    "    \"topic_drift_rate\": [\"topic\"]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb401340",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def detect_language(text, model):\n",
    "    \"\"\"Returns language code (e.g., 'en', 'fr')\"\"\"\n",
    "    if model is None or pd.isna(text) or str(text).strip() == \"\":\n",
    "        return 'en' \n",
    "    \n",
    "    clean_text = str(text).replace(\"\\n\", \" \")\n",
    "    try:\n",
    "        predictions = model.predict(clean_text)\n",
    "        lang = predictions[0][0].replace(\"__label__\", \"\")\n",
    "        return lang\n",
    "    except:\n",
    "        return 'en'\n",
    "\n",
    "def translate_to_english(client, text):\n",
    "    \"\"\"Uses Groq to translate text to English.\"\"\"\n",
    "    if pd.isna(text) or str(text).strip() == \"\":\n",
    "        return \"\"\n",
    "        \n",
    "    system_instruction = \"You are a translator. Translate the following text into English. Output ONLY the translation, nothing else.\"\n",
    "    \n",
    "    try:\n",
    "        chat_completion = client.chat.completions.create(\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_instruction},\n",
    "                {\"role\": \"user\", \"content\": text}\n",
    "            ],\n",
    "            model=\"llama-3.3-70b-versatile\",\n",
    "            temperature=0,\n",
    "            max_tokens=1024,\n",
    "        )\n",
    "        return chat_completion.choices[0].message.content.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Translation Error: {e}\")\n",
    "        return text # Fallback to original\n",
    "\n",
    "def check_specific_keywords(text, metric_name):\n",
    "    \"\"\"\n",
    "    Checks if the text contains the specific keywords mapped to the metric.\n",
    "    \"\"\"\n",
    "    if pd.isna(text): return False\n",
    "    text_lower = str(text).lower()\n",
    "    \n",
    "    # Get keywords for this metric\n",
    "    target_words = KEYWORD_MAPPING.get(metric_name, [])\n",
    "    \n",
    "    if not target_words:\n",
    "        return False\n",
    "        \n",
    "    # Check if ANY of the target words are in the text\n",
    "    for word in target_words:\n",
    "        if word in text_lower:\n",
    "            return True\n",
    "            \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40594168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastText model loaded.\n",
      "Processing 500 rows...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:45<00:00, 10.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Processing Complete.\n",
      "Total scores boosted: 82\n",
      "Saved to: updated_submission_metric_shuffle.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Init Models\n",
    "client = Groq(api_key=GROQ_API_KEY)\n",
    "try:\n",
    "    ft_model = fasttext.load_model(FASTTEXT_PATH)\n",
    "    print(\"FastText model loaded.\")\n",
    "except:\n",
    "    print(\"FastText model not found. Defaulting to English.\")\n",
    "    ft_model = None\n",
    "# 2. Load Data\n",
    "df_prompts = pd.read_json(INPUT_JSON_PATH)\n",
    "if 'id' not in df_prompts.columns:\n",
    "    df_prompts['id'] = range(1, len(df_prompts) + 1)\n",
    "df_scores = pd.read_csv(INPUT_SCORES_PATH)\n",
    "# Merge\n",
    "merged_df = pd.merge(df_scores, df_prompts, on='id', how='left')\n",
    "merged_df=merged_df[:500]\n",
    "\n",
    "print(f\"Processing {len(merged_df)} rows...\")\n",
    "boost_count = 0\n",
    "# 3. Process Rows\n",
    "for index, row in tqdm(merged_df.iterrows(), total=merged_df.shape[0]):\n",
    "    \n",
    "    metric = row['metric_name']\n",
    "    sys_p = row.get('system_prompt', '')\n",
    "    usr_p = row.get('user_prompt', '')\n",
    "    current_score = row['score']\n",
    "    \n",
    "    # Only process if we have a keyword rule for this metric\n",
    "    if metric in KEYWORD_MAPPING:\n",
    "        \n",
    "        # A. Detect Language on User Prompt\n",
    "        lang = detect_language(usr_p, ft_model)\n",
    "        \n",
    "        # B. Prepare English Text\n",
    "        final_text_to_check = \"\"\n",
    "        \n",
    "        if lang != 'en':\n",
    "            # Translate System Prompt\n",
    "            if pd.notna(sys_p) and str(sys_p).strip() != \"\":\n",
    "                sys_p_en = translate_to_english(client, sys_p)\n",
    "            else:\n",
    "                sys_p_en = \"\"\n",
    "                \n",
    "            # Translate User Prompt\n",
    "            usr_p_en = translate_to_english(client, usr_p)\n",
    "            \n",
    "            final_text_to_check = f\"{sys_p_en} {usr_p_en}\"\n",
    "        else:\n",
    "            # Already English\n",
    "            final_text_to_check = f\"{sys_p} {usr_p}\"\n",
    "\n",
    "        # C. Check Keywords in the (Translated) Prompts\n",
    "        has_keyword = check_specific_keywords(final_text_to_check, metric)\n",
    "        \n",
    "        # D. Apply Logic: If Present AND Score < 5 -> Set to 7\n",
    "        if has_keyword:\n",
    "            if current_score < 5.0:\n",
    "                to_add= 7.0-current_score\n",
    "                np.floor(to_add)\n",
    "                merged_df.at[index, 'score'] = current_score+to_add\n",
    "                boost_count += 1\n",
    "# 4. Save\n",
    "final_df = merged_df[['id', 'score']]\n",
    "final_df.to_csv(OUTPUT_CSV_PATH, index=False)\n",
    "print(\"-\" * 30)\n",
    "print(f\"Processing Complete.\")\n",
    "print(f\"Total scores boosted: {boost_count}\")\n",
    "print(f\"Saved to: {OUTPUT_CSV_PATH}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hackathon2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
